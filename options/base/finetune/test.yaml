datasets:
  train:
    # data loadecr
    num_worker_per_gpu: 8
    batch_size_per_gpu: 1
    dataset_enlarge_ratio: 99999
    prefetch_mode: ~

# training settings
train:
  generalize_first: true

  # losses
  pixel_opt:
    type: L1Loss
    loss_weight: 1.0
    reduction: mean

  total_iter: 10000
  align_iter: 8000
  oomn_iter: 2000
  warmup_iter: -1  # no warm up

  align_opt:
    optim_g:
      type: Adam
      lr: !!float 5e-5
      weight_decay: 0
      betas: [0.9, 0.999]

    scheduler:
      type: HandieLR
      milestones: [999999]
      lrs: [0]

  oomn_opt:
    optim_g:
      type: Adam
      lr: !!float 1e-5
      weight_decay: 0
      betas: [0.9, 0.999]

    scheduler:
      type: HandieLR
      milestones: [999999]
      lrs: [0]
