{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on the Few-shot RAW Image Denoising Track of the MIPI Workshop\n",
    "\\[[Homepage](https://mipi-challenge.org/MIPI2024/)\\] \\[[Codalab](https://codalab.lisn.upsaclay.fr/competitions/17017)\\]\n",
    "\n",
    "In this tutorail, we will go through the steps of the RAW image denoising task, including:\n",
    "\n",
    "- **Dataset**: How to read and load paired data from the dataset.\n",
    "- **Lite ISP for processing the RAW image**: How to visualize the processed raw images.\n",
    "- **Score Calculation**: Get quantitative metrics to evaluate performance.\n",
    "- **Submission**: How to create a zip file that complies with submission format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "## add current path to the enviorment\n",
    "sys.path.append(os.path.abspath(os.path.dirname(__file__)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "> Source code can be found in `tools/mipi_starting_kit/code_example/dataset.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The dataset can be also found in `led/data/mipi_dataset.py`\n",
    "## In this way you could use our codebase for both training and evaluation.\n",
    "from dataset import MIPIDataset\n",
    "\n",
    "opt = {\n",
    "    ## Basic options of the dataset\n",
    "    'phase': 'train',                           # the phase: train or valid\n",
    "    'dataroot': 'path/to/your/dataset',         # the path to our released dataset\n",
    "    'data_pair_list': 'path/to/your/pair/list', # the path to the txt file of the mipi dataset\n",
    "    ## Augmentation options\n",
    "    'crop_size': 1024,                          # whether to crop the paired data (center crop when not in train phase)\n",
    "    'use_hflip': True,                          # whether to use the flip augmentation\n",
    "    'use_rot':   True,                          # whether to use the rotation augmentation\n",
    "}\n",
    "\n",
    "dataset = MIPIDataset(opt)\n",
    "\n",
    "for paired_data in dataset:\n",
    "    \"\"\"\n",
    "    Operate with the data, the `paired_data` are composed as below:\n",
    "    {\n",
    "        'lq': lq_im_patch,      # the input patch in (4, crop_size, crop_size). torch.Tensor\n",
    "        'gt': gt_im_patch,      # the gt patch, same size with lq. torch.Tensor\n",
    "        'ratio': ratio,         # the value of the additional dgain. torch.Tensor\n",
    "        'wb': gt_wb,            # the white balance of gt in (3, 1, 1). torch.Tensor\n",
    "        'ccm': gt_ccm,          # the cam2rgb matrix in (3, 3). torch.Tensor\n",
    "        'lq_path': lq_path,     # the path to the input npz file. str\n",
    "        'gt_path': gt_path      # the path to the gt npz file. str\n",
    "    }\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lite ISP\n",
    "> We utilze a simplified version of the [ELD](https://github.com/Vandermode/ELD). \n",
    ">\n",
    "> Source code can be found in `tools/mipi_starting_kit/code_example/lite_isp.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import depack_meta, calculate_ratio    # for load data\n",
    "from lite_isp import process\n",
    "\n",
    "## load data\n",
    "example_meta_path = 'path/to/the/npz/file'\n",
    "raw, wb, cam2rgb = depack_meta(example_meta_path, to_tensor=True)\n",
    "\n",
    "## amplified the raw image\n",
    "ratio = calculate_ratio(example_meta_path)\n",
    "amplified_raw = (raw * ratio).clamp(0.0, 1.0)\n",
    "\n",
    "## prepare for process\n",
    "## the process function only support batch format, which is (B, 4, H, W)\n",
    "batch_raw = amplified_raw.unsqueeze(0)\n",
    "wbs       = wb.unsqueeze(0)\n",
    "cam2rgbs  = cam2rgb.unsqueeze(0)\n",
    "\n",
    "## process!\n",
    "rgb = process(batch_raw, wbs, cam2rgbs, gamma=2.2)\n",
    "\n",
    "## save the image\n",
    "from torchvision.utils import save_image\n",
    "# we save the gt image with the `save_image` function provided by torchvision too\n",
    "save_image(rgb, 'path/to/save/the/image.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Calculation\n",
    "\n",
    "> Since raw images take up a lot of storage space, and codalab only supports uploading a zip packages of up to 300MB. we calculate the metric on 8-bit pngs (in sRGB color space). \n",
    "> \n",
    "> And the 8bit png data in sRGB space **MUST** be rendered by the [Lite ISP](#lite-isp) we provide. We will double check the contestants' codes at the end to ensure fairness.\n",
    "\n",
    "The score is calculated with both PSNR and SSIM.\n",
    "\n",
    "$$Score=\\log_k(SSIM*k^{PSNR})=PSNR+\\log_k(SSIM)$$\n",
    "\n",
    "In our implementation, $k=1.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from score import calculate_score\n",
    "\n",
    "## load images\n",
    "# We utilize the io.imread from skimage too on the codalab server.\n",
    "result = io.imread('path/to/the/result.png')\n",
    "gt     = io.imread('path/to/the/gt.png')\n",
    "\n",
    "## calculate the score\n",
    "score = calculate_score(result, gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "The validation/test data are provided in the following format:\n",
    "```bash\n",
    "|-- test\n",
    "|   |-- Camera1\n",
    "|   |   `-- short\n",
    "|   |       |-- 00002_05_33.33333333333333.npz\n",
    "|   |       `-- ...\n",
    "|   `-- Camera2\n",
    "|       `-- short\n",
    "|           |-- 00002_25_33.33333333333333.npz\n",
    "|           `-- ...\n",
    "`-- valid\n",
    "    |-- Camera1\n",
    "    |   `-- short\n",
    "    |       |-- 00001_05_33.33333333333333.npz\n",
    "    |       `-- ...\n",
    "    `-- Camera2\n",
    "        `-- short\n",
    "            |-- 00001_25_33.33333333333333.npz\n",
    "            `-- ...\n",
    "```\n",
    "\n",
    "And as your submission, you should upload a zip file which are as the following format:\n",
    "\n",
    "```bash\n",
    "|-- test.zip\n",
    "|   |-- Camera1\n",
    "|   |   |-- 00002_05_33.33333333333333.png\n",
    "|   |   `-- ...\n",
    "|   `-- Camera2\n",
    "|       |-- 00002_25_33.33333333333333.png\n",
    "|       `-- ...\n",
    "`-- valid.zip\n",
    "    |-- Camera1\n",
    "    |   |-- 00001_05_33.33333333333333.png\n",
    "    |       `-- ...\n",
    "    `-- Camera2\n",
    "        |-- 00001_25_33.33333333333333.png\n",
    "        `-- ...\n",
    "```\n",
    "\n",
    "Here are a few points to pay special attention to:\n",
    "- Different zip (test.zip/valid.zip) should be upload to different phase of our challenge.\n",
    "- There is no longer a subfolder `short` under `Camera1` or `Camera2`\n",
    "- The output image should be the same name with the input (except the suffix).\n",
    "- The uploaded image should be 8-bit png images, and **MUST** be rendered by the [Lite ISP](#lite-isp) we provide.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" A simple demo for output the image \"\"\"\n",
    "import os\n",
    "from glob import glob\n",
    "from dataset import calculate_ratio, depack_meta\n",
    "from lite_isp import process\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "cameras = ['Camera1', 'Camera2']\n",
    "data_path = 'path/to/the/valid/data'\n",
    "save_path = 'path/to/save'\n",
    "\n",
    "my_algo = lambda x, camera: x       # a function for process the image\n",
    "                                    # you could use different weights for different cameras\n",
    "\n",
    "for curr_cam in cameras:\n",
    "    os.makedirs(f'{save_path}/{curr_cam}', exist_ok=True)\n",
    "    input_npzs = list(sorted(glob(f'{data_path}/*.npz')))\n",
    "    for input_npz in input_npzs:\n",
    "        ## load and prepare data\n",
    "        ratio = calculate_ratio(input_npz)\n",
    "        im, wb, cam2rgb = depack_meta(input_npz, to_tensor=True)\n",
    "        im = (im * ratio).clamp(None, 1.0).unsqueeze(0)\n",
    "        wb = wb.unsqueeze(0)\n",
    "        cam2rgb = cam2rgb.unsqueeze(0)\n",
    "\n",
    "        ## denoising\n",
    "        out = my_algo(im, curr_cam)\n",
    "\n",
    "        ## perform lite isp and save image\n",
    "        rgb = process(out, wb, cam2rgb, gamma=2.2)\n",
    "\n",
    "        ## save image\n",
    "        curr_im_name = os.path.basename(input_npz).replace('.npz', '.png')\n",
    "        save_image(rgb, f'{save_path}/{curr_cam}/{curr_im_name}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
